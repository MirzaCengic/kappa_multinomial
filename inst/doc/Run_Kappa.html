<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">



<title>Kappa multinomial</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">Kappa multinomial</h1>



<div id="this-is-a-brief-tutorial-for-using-kappa_multinomial-a-new-way-to-assess-the-performance-of-multinomial-predictions-for-landcover" class="section level1">
<h1>This is a brief tutorial for using <span class="math inline">\(\kappa_{multinomial}\)</span>, a new way to assess the performance of multinomial predictions for landcover</h1>
<p>First install the packages. Here we use the library <code>gtools</code> to generate some data to simulate data for testing purposes.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#install.packages(&quot;devtools&quot;)</span>
devtools::<span class="kw">install_github</span>(<span class="st">&quot;bobdouma/kappa_multinomial&quot;</span>)
<span class="kw">library</span>(multinomialperform)
<span class="co">#install.packages(&quot;gtools&quot;)</span>
<span class="kw">library</span>(gtools)</code></pre></div>
<p>In the simplest case there is a matrix (or data frame) of predictions and a data frame of observations. Both of these can either be binary or continuous probablities. But all cells of both matrixes must be <span class="math inline">\(0&lt;=y_{i}&lt;=1\)</span>. The columns of both matrices correspond to <span class="math inline">\(q\)</span> land cover classes. Each row is a sample <span class="math inline">\(i\)</span>. Further for the modelled class probabilities and the class observations it should hold that <span class="math inline">\(\sum_{k=1}^q y_{ik} =1\)</span> and <span class="math inline">\(\sum_{k=1}^m p_{ik} = 1\)</span>.Not that one of the advances of this approach is that uncertainty in the observations can be represented. The order of the rows for the land cover classes in the observed and predicted matrices should correspond exactly.</p>
<p><span class="math inline">\(\kappa_{multinomial}\)</span> can be calculated as the product of <span class="math inline">\(\kappa_{loc} * \kappa_{prob} = \frac{p_{0 multinomial} - p_{e multinomial}}{p_{max}-p_{e multinomial}} * \frac{p_{max} - p_{e multinomial}}{1-p_{e multinomial}}\)</span></p>
<p><span class="math inline">\(\kappa_{prob}\)</span> measures the degree to which ranks of the predicted class probabilities correspond to the ranks of the observed class frequencies. It thus reaches one if there is a perfect match between the rank orders of the observations and predictions. It reaches zero if the model has similar performance compared to the null model. <span class="math inline">\(\kappa_{loc}\)</span> in turn, measures the certainty of the model in the case of discrete observations. For continuous observations, <span class="math inline">\(\kappa_{loc}\)</span> measures the mean match of the sorted observed and predicted sample frequencies. <span class="math inline">\(\kappa_{loc}\)</span> equals zero if the performance of the multinomial equals the null model. It equals one if, for each sample, the sorted predictions exactly matches the sorted observations.</p>
<div id="case-1-predictions-are-continuous-probabilities-and-observations-discrete" class="section level3">
<h3>Case 1: Predictions are continuous probabilities and observations discrete</h3>
<p>In this case we show an example where the observed classes are predicted to be most likely. This implies that <span class="math inline">\(\kappa_{prob}\)</span> should equal to one and <span class="math inline">\(\kappa_{loc}\)</span> will depend on the average certainty with which the observed classes are predited</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred =<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">rdirichlet</span>(<span class="dv">100</span>, <span class="kw">c</span>(<span class="fl">0.1</span>,<span class="fl">0.1</span>,<span class="fl">0.5</span>,<span class="fl">0.5</span>))) <span class="co"># generate multinomial probabilties with four classes</span>
pred =<span class="st"> </span><span class="kw">t</span>(<span class="kw">apply</span>(pred,<span class="dv">1</span>,sample)) <span class="co"># randomly shuffles the columns for each sample; otherwise only one class is most likely</span>
obs =<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">prob_to_binary</span>(pred)) <span class="co"># prob_to_binary transforms probabilities to discrete outcomes, 1 for the most probable class, 0's for the remaining classes </span>
<span class="kw">kappa_multinomial</span>(<span class="dt">obs=</span>obs,<span class="dt">pred=</span>pred) <span class="co"># calculate kappa</span></code></pre></div>
<pre><code>##  k_prob     k_loc k_multinomial        po     pe      pmax
##       1 0.6570035     0.6570035 0.7516019 0.2758 0.7516019</code></pre>
</div>
<div id="case-2-predictions-are-continuous-probabilities-and-observations-discrete" class="section level3">
<h3>Case 2: Predictions are continuous probabilities and observations discrete</h3>
<p>In this case we show an example where the observed classes are predicted to be most likely. However, the certainty with which the classes are predicted is much higher. Again, <span class="math inline">\(\kappa_{prob}\)</span> should equal to one and <span class="math inline">\(\kappa_{loc}\)</span> will depend on the average certainty with which the observed classes are predited</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred =<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">rdirichlet</span>(<span class="dv">100</span>, <span class="kw">c</span>(<span class="fl">0.1</span>,<span class="fl">0.1</span>,<span class="fl">4.5</span>,<span class="fl">0.5</span>))) <span class="co"># generate multinomial probabilties with four classes</span>
pred =<span class="st"> </span><span class="kw">t</span>(<span class="kw">apply</span>(pred,<span class="dv">1</span>,sample))
obs =<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">prob_to_binary</span>(pred))
<span class="kw">kappa_multinomial</span>(<span class="dt">obs=</span>obs,<span class="dt">pred=</span>pred) <span class="co"># calculate kappa</span></code></pre></div>
<pre><code>##  k_prob     k_loc k_multinomial        po     pe      pmax
##       1 0.8274338     0.8274338 0.8706789 0.2506 0.8706789</code></pre>
</div>
<div id="case-3-predictions-are-continuous-probabilities-and-observations-discrete" class="section level3">
<h3>Case 3: Predictions are continuous probabilities and observations discrete</h3>
<p>In this case we show an example where there is mismatch between the observed classes and the classes predicted to be most likely. <span class="math inline">\(\kappa_{loc}\)</span> remains similar as the previous example. However <span class="math inline">\(\kappa_{prob}\)</span> becomes lower than one.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">obs =<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">prob_to_binary</span>(pred))  <span class="co"># transform probs to 0,1 (1 being the most likely)</span>
resample =<span class="st"> </span><span class="kw">sample</span>(<span class="kw">c</span>(<span class="dv">1</span>:<span class="dv">100</span>),<span class="dv">20</span>) <span class="co"># randomly pick 20 observations</span>
obs[resample,] =<span class="st"> </span>obs[<span class="kw">sample</span>(resample),] <span class="co"># randomly shuffle 20 observations</span>
<span class="kw">kappa_multinomial</span>(<span class="dt">obs=</span>obs,<span class="dt">pred=</span>pred) <span class="co"># calculate kappa</span></code></pre></div>
<pre><code>##     k_prob     k_loc k_multinomial        po     pe      pmax
##  0.8048916 0.8274338     0.6659945 0.7496963 0.2506 0.8706789</code></pre>
</div>
<div id="case-4-predictions-are-continuous-probabilities-and-observations-not-discrete" class="section level3">
<h3>Case 4: Predictions are continuous probabilities and observations not discrete</h3>
<p>In this case we show an example wehere prediction frequency is equal to observed frequency. In this case _{multinomial} should equal 1, indicating perfect model performance.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred =<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">rdirichlet</span>(<span class="dv">100</span>, <span class="kw">c</span>(<span class="fl">0.1</span>,<span class="fl">0.1</span>,<span class="fl">0.5</span>,<span class="fl">0.5</span>))) <span class="co"># generate multinomial probabilties with four classes</span>
obs =<span class="st"> </span>pred
<span class="kw">kappa_multinomial</span>(<span class="dt">obs=</span>obs,<span class="dt">pred=</span>pred) <span class="co"># calculate kappa</span></code></pre></div>
<pre><code>## [1] &quot;Observations are not discrete. A randomization procedure is used to calculate pe. Consider adjusting nsim&quot;
## ========================================================================================================================</code></pre>
<pre><code>##  k_prob k_loc k_multinomial po       pe pmax
##       1     1             1  1 0.455232    1</code></pre>
</div>
<div id="case-5-observations-not-discrete-and-prediction-frequency-random-relative-to-observed" class="section level3">
<h3>Case 5: Observations not discrete and prediction frequency random relative to observed</h3>
<p>In this case the evaluation of the model should find that <span class="math inline">\(\kappa_{prob}\)</span> preforms poorly, while the maximum model fit of a model with this set of modelled class distributions for the set of observations, <span class="math inline">\(\kappa_{loc}\)</span> is one.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pred =<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">rdirichlet</span>(<span class="dv">100</span>, <span class="kw">c</span>(<span class="fl">0.1</span>,<span class="fl">0.1</span>,<span class="fl">0.5</span>,<span class="fl">0.5</span>))) <span class="co"># generate multinomial probabilties with four classes</span>
obs =<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">t</span>(<span class="kw">apply</span>(pred,<span class="dv">1</span>,sample))) <span class="co"># randomly shuffle observations</span>
<span class="kw">kappa_multinomial</span>(<span class="dt">obs=</span>obs,<span class="dt">pred=</span>pred,<span class="dt">nsim=</span><span class="dv">10000</span>) <span class="co"># calculate kappa</span></code></pre></div>
<pre><code>## [1] &quot;Observations are not discrete. A randomization procedure is used to calculate pe. Consider adjusting nsim&quot;
## ========================================================================================================================</code></pre>
<pre><code>##      k_prob k_loc k_multinomial        po        pe pmax
##  0.05816825     1    0.05816825 0.3819062 0.3437323    1</code></pre>
</div>
<div id="case-6-observations-not-discrete-and-the-most-likely-class-to-be-observed-is-predicted-with-lower-probability.-however-the-ranking-within-a-sample-remains-the-same." class="section level3">
<h3>Case 6: Observations not discrete and the most likely class to be observed is predicted with lower probability. However the ranking within a sample remains the same.</h3>
<p>Observations not discrete: The observations are generated such that the class predicted with higest probability is observed to be a bit less likely (val). The ranking of the sample probabilities remain the same; hence <span class="math inline">\(\kappa_{prob}\)</span> is close to one (not exactly because if the class that is predicted with highest probablity is smaller than the second highest class after subtracting val than the ranking is changed). In contrast <span class="math inline">\(\kappa_{loc}\)</span> decreases.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">increase =<span class="st"> </span>function(x,<span class="dt">val=</span><span class="fl">0.05</span>){
  for (i in <span class="dv">1</span>:<span class="kw">nrow</span>(x)){
  x[i,<span class="kw">which.max</span>(x[i,])] =<span class="st">  </span>x[i,<span class="kw">which.max</span>(x[i,])] -<span class="st"> </span>val
  x[i,-<span class="kw">which.max</span>(x[i,])] =<span class="st"> </span>x[i,-<span class="kw">which.max</span>(x[i,])]+<span class="st">   </span>val/(<span class="kw">ncol</span>(x)-<span class="dv">1</span>)
  }
  <span class="kw">return</span>(x)
}

pred =<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">rdirichlet</span>(<span class="dv">100</span>, <span class="kw">c</span>(<span class="fl">0.1</span>,<span class="fl">0.1</span>,<span class="fl">0.5</span>,<span class="fl">0.5</span>))) <span class="co"># generate multinomial probabilties with four classes</span>
obs =<span class="st"> </span>pred <span class="co"># randomly shuffle observations</span>

pred.lower=<span class="st"> </span><span class="kw">increase</span>(pred,<span class="dt">val=</span><span class="fl">0.1</span>)

<span class="kw">kappa_multinomial</span>(<span class="dt">obs=</span>obs,<span class="dt">pred=</span>pred) <span class="co"># calculate kappa</span></code></pre></div>
<pre><code>## [1] &quot;Observations are not discrete. A randomization procedure is used to calculate pe. Consider adjusting nsim&quot;
## ========================================================================================================================</code></pre>
<pre><code>##  k_prob k_loc k_multinomial po        pe pmax
##       1     1             1  1 0.4857559    1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">kappa_multinomial</span>(<span class="dt">obs=</span>obs,<span class="dt">pred=</span>pred.lower) <span class="co"># calculate kappa</span></code></pre></div>
<pre><code>## [1] &quot;Observations are not discrete. A randomization procedure is used to calculate pe. Consider adjusting nsim&quot;
## ========================================================================================================================</code></pre>
<pre><code>##     k_prob     k_loc k_multinomial    po        pe      pmax
##  0.9986912 0.8123802      0.811317 0.903 0.4859103 0.9035466</code></pre>
</div>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
