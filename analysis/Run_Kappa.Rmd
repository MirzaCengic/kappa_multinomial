---
output: html_document
---
```{r global_options, include = FALSE}
library(knitr)
options(width = 120)
opts_chunk$set(fig.width = 12, fig.height = 8, fig.path = 'Figs/',
               echo=TRUE,results="markup",eval=TRUE,
               include = TRUE, warning = FALSE, message = FALSE)
```


# This is a brief tutorial for using `kappa_multinomial`, a new way to assess the performance of multinomial predictions for landcover

First install the packages.  Here we use the library `gtools` to generate some data to simulate data for testing purposes.

```{R,eval = TRUE}
#install.packages("devtools")
devtools::install_github("bobdouma/kappa_multinomial")
library(multinomialperform)
#install.packages("gtools")
library(gtools)
```


In the simplest case there is a matrix (or data frame) of predictions and a data frame of observations.  Both of these can either be binary or continuous probablities.  But all cells of both matrixes must be $0<=x<=1$.  The columns of both matrices correspond to land cover classes $k$.  Each row is a sample $i$. Further for the modelled class probabilities and the class observations it should hold that $\sum_{i=1}^m y_{ik} =1$ and  $\sum_{i=1}^m p_{ik} = 1$.Not that one of the advances of this approach is that uncertainty in the observations can be represented.  The order of the rows for the land cover classes in the observed and predicted matrices should correspond exactly.    

### case 1: Predictions are continuous probabilities and observations discrete

In this case we show an example where the observed classes are predicted to be most likely. This implies that $k_prob$ should equal to one and $k_loc$ will depend on the average certainty with which the observed classes are predited

```{R,eval = TRUE}
pred = as.data.frame(rdirichlet(100, c(0.1,0.1,0.5,0.5))) # generate multinomial probabilties with four classes
pred = t(apply(pred,1,sample))
obs = as.data.frame(prob_to_binary(pred))
kappa_multinomial(obs=obs,pred=pred) # calculate kappa
```


### case 2: Predictions are continuous probabilities and observations discrete

In this case we show an example where the observed classes are predicted to be most likely. However, the certainty with which the classes are predicted is much higher.


```{R,eval = TRUE}
pred = as.data.frame(rdirichlet(100, c(0.1,0.1,4.5,0.5))) # generate multinomial probabilties with four classes
pred = t(apply(pred,1,sample))
obs = as.data.frame(prob_to_binary(pred))
kappa_multinomial(obs=obs,pred=pred) # calculate kappa
```


### case 3: Predictions are continuous probabilities and observations discrete

In this case we show an example where there is mismatch between the observed classes and the classes predicted to be most likely. $k_loc$ remains similar as the previous example. However $k_prob$ becomes lower than one. 


```{R,eval = TRUE}
pred = as.data.frame(rdirichlet(100, c(0.1,0.1,4.5,0.5))) # generate multinomial probabilties with four classes
pred = t(apply(pred,1,sample))
obs = as.data.frame(prob_to_binary(pred))  # transform probs to 0,1 (1 being the most likely)
resample = sample(c(1:100),20) # randomly pick 20 observations
obs[resample,] = obs[sample(resample),] # randomly shuffle 20 observations
kappa_multinomial(obs=obs,pred=pred) # calculate kappa
```


### case 4: Predictions are continuous probabilities and observations not discrete

In this case we show an example wehere prediction frequency is equal to observed frequency.  In this case kappa_multinomial should equal 1, indicating perfect model performance.   

```{R,eval = TRUE}
pred = as.data.frame(rdirichlet(100, c(0.1,0.1,0.5,0.5))) # generate multinomial probabilties with four classes
obs = pred
kappa_multinomial(obs=obs,pred=pred) # calculate kappa
```

### case 5: Observations not discrete and prediction frequency random relative to observed

In this case the evaluation of the model should find that $k_prob$ preforms poorly, while the maximum model fit of a model with this set of modelled class distributions for the set of observations, $k_loc$ is one.  

```{R,eval = TRUE}
pred = as.data.frame(rdirichlet(100, c(0.1,0.1,0.5,0.5))) # generate multinomial probabilties with four classes
obs = as.data.frame(t(apply(pred,1,sample))) # randomly shuffle observations
kappa_multinomial(obs=obs,pred=pred) # calculate kappa
```

### case 3: ## tot hier gekomen

Observations not discrete: The observations are generated such that the class predicted with higest probability is observed to be a bit less likely (val) 

Note: here I expect that the old method of calculating pmax will fail because $(p_o-p_e) > (p_{max}-p_e)$

```{R,eval = TRUE}
increase = function(x,val=0.1){
  for (i in 1:nrow(x)){
  x[i,which.max(x[i,])] =  x[i,which.max(x[i,])] - val
  x[i,-which.max(x[i,])] = x[i,-which.max(x[i,])]+   val/(ncol(x)-1)
  }
  return(x)
}

pred.case3= increase(pred,val=0.1)

kappa_multinomial(obs=obs,pred=pred.case3) # calculate kappa
```

 Note that $k_prob > 1$ when using the old method of calculating pmax
 Note that $k_prob \approx 1$ when using the new method. This makes sense. The model is right in predicting the ranking of the most likely classes; however it is wrong in predicting the accurate probability to each class. 
 
### case 4: a more realistic case in which the observations are generated by sampling from the probabilities
 
```{R,eval = TRUE}
# generate multinomial probabilties with four classes
pred = as.data.frame(rdirichlet(100, c(0.1,0.1,0.5,0.5))) 
# generate multinomial observations with four classes
 obs = as.data.frame(t(apply(pred,1,rmultinom,size=1,n=1))) 
 # calculate kappa
 kappa_multinomial(obs=obs,pred=pred) 
```
 
